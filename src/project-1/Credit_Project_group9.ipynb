{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {margin-left: 0 !important}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {margin-left: 0 !important}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 \n",
    "### Group 9\n",
    "#### Adrian Eriksen, Maren Aamodt, Anette Fredriksen\n",
    "\n",
    "The label in the dataset represent information about persons who has taken out a loan, the response vaiable is if they paid the loan back or not. With 1 beeing they paid back and 2 that they did not. In our project we use action that have values 1 and 0, where 1 is when the money is paid back and 0 is when it is not paid back. Therefore we need to map 2 to 0, this is done in TestLending.py. We assume that the vaiables employment, credit history and other debtors are some of vaiables that have most influence on if the lend money is paid back. \n",
    "\n",
    "#### The data  \n",
    "\n",
    "| Numerical features |     |                |             |        |         |         |\n",
    "|:-------------------|:----|:---------------|:------------|:-------|:--------|:--------|\n",
    "|  Duration          | Age | Residence time | Installment | Amount | Persons | Credits |  \n",
    "\n",
    "| Qualitative features |       |                    |                |         |          |         |\n",
    "|:---------------------|:------|:-------------------|:---------------|:--------|:---------|:--------|\n",
    "| Account balance      | Job   | Other installments | Employment     | Housing | Property | Foreign |\n",
    "| Credit history       | Phone | Other debtors      | Marital Status | Purpose | Savings  |  \n",
    "   \n",
    "The training and test dataset is from a German bank. In the dataset it is 20 features and one response variable: 'checking account balance', 'duration', 'credit history', 'purpose', 'amount', 'savings', 'employment', 'installment', 'marital status', 'other debtors', 'residence time', 'property', 'age', 'other installments', 'housing', 'credits', 'job', 'persons', 'phone', 'foreign'.\n",
    "It is not sure that the same variables that make germans pay back loan is the same as in e.g Norway, this sould be taken into accunt before applying this dataset in other countries.  \n",
    "\n",
    "\n",
    "#### Program structure\n",
    "\n",
    "fit() fits a Naive Bayes model. \n",
    "\n",
    "set_interest_rate() sets the interest rate.\n",
    "\n",
    "predict_proba() uses the model made in fit() to predict probability for a given x (person).\n",
    "\n",
    "expected_utility() uses predict_proba() to get a prediction probability.\n",
    "\n",
    "get_best_action() uses expected_utility() and checks if the expected return is possitive, if the return is positive a loan is granted. \n",
    "\n",
    "We made a helper function in TestLending.py, mapping. Mapping sets 2 to 0 in the response vaiable (when loan was not payed back). \n",
    "#### Model development\n",
    "\n",
    "We choose Naive Bayes to fit our model, this is done with sklearn using Multinomial Naive Bayes. Naive Bayes is good with classification problems. We did not use action as a parameter in expected_utility, since we used the prediction percentage from fit for is a person pays back. We used the prediction for calculating the probable income or loss. It will be a loss of income if the person does not pay back, so if fit function predicted a low possibility of getting paid back we will not grant a loan. The formula we used is:\n",
    "\n",
    "predicted probability for return * sum of loan * (1 + intrest rate)^months of loan - preicted probability for no return *sum of loan.\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "#### Results for name_banker:\n",
    "\n",
    "Average utility: 1173660.8979637849\n",
    "\n",
    "Average return on investment: 180.21184835525688\n",
    "\n",
    "\n",
    "#### Results for random_banker:\n",
    "\n",
    "Average utility: 566096.2579925589\n",
    "\n",
    "Average return on investment: 83.07326428354087\n",
    "\n",
    "We can se from the result that our model outpreform random_banker by a lot.\n",
    "This is expected since random banker is not considereing any variables when granting loans. \n",
    "Our average return on investment is 216,9% higher than random_banker. \n",
    "\n",
    "## Part 2  \n",
    "### 1.\n",
    "#### Is it possible to ensure that your policy maximises revenue?\n",
    "We can never completley assure that our policy maximises revenue, but we can maximise expected revenue. The reason for this is that one can never be sure whether a person will be able to repay a loan.  \n",
    "#### How can you take into account the uncertainty due to the limited and/or biased data?\n",
    "Taking the uncertainty of our limited and/or biased data into account is hard when we do not have a different dataset to test it up against. If we had this second dataset, we would at least be able to somewhat increase our certainty, based on the fact that we would have information from more than one source. Especially now, during a pandemic, we find it harder to trust data regarding economy and credit worthiness that's collected pre-corona. One way we could deal with this would be to create new data based on the one we posses, but if our original data is inherently flawed, then this might make the model worse. Another way would be to increase the expected utility necessary for granting loans, so that we take fewer risks. We could obviously also increase the interest rate, but in a real world scenario this might just lead to fewer customers and reduce our income.  \n",
    "#### What if you have to decide credit for thousands of individuals and your model is wrong? How should you take that type of risk into account?\n",
    "First of all, we could start out small with deciding credit for e.g 1000 people. After that we could see how well the model preformed and decide whether to make any adjustments. Another option is to start with only granting loans under a certain amount to make sure that we don't go bankrupt if our model is wrong. We could also create a threshold by finding the standard deviation and mean of expected utility and only grant loans within a given range.  \n",
    "Proposed algorithm: We want to have a maximum loan limit, because the loss would be high for large loans if our model does not work. Also, we want to have a minimum expected utility, so that loans with low utility (and smaller chance of the loaner repaying the loan) are rejected. In this way, we minimize the damage if it turns out our model is flawed. Also, as explained above, we limit the number of loaners to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-18158df50ba8>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-18158df50ba8>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    #<do not grant loan>\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Pseudocode:\n",
    "nr_of_loaners = 0 #Limiting nr of loaners to 1000 persons\n",
    "\n",
    "if(loan_size < max_loan \n",
    "and expected_utility > min_utility \n",
    "and nr_of_loaners <= 1000):\n",
    "    #<grant loan>\n",
    "    nr_of_loaners += 1\n",
    "else:\n",
    "    #<do not grant loan>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "#### Does the existence of this database raise any privacy concerns?  \n",
    "Yes. First of all, we have the status of their current checking account, credit history and savings accounts. While this in itself might not raise any concerns, one can use their employment status, personal status and sex, property, housing status, age and job to concievably learn who this person is. This may not apply for all people in the database, but a lot of people have little regard for what information they make publicly available through Facebook and other social media. One must also consider the fact that this is the kind of information sought after by hackers, who usually have sophisticated ways of retrieving data from different sources. If the data in this database was made publicly available, it would not be hard for someone with the right skill set to learn the name of most people in the database.  \n",
    "#### If the database was secret (and only known by the bank), but the credit decisions were public, how would that affect privacy?  \n",
    "Making the database only available to the bank would significantly increase the privacy of the data. Making the credit decisions public would not necessarily affect this if there was no other metadata (like the time of the request) published. Given that we have two counters, one for yes and one for no, we find it hard to believe that someone could learn whether a given person is credit worthy based on this alone. That being said, the database only being known to the bank, doesn't necessarily guarantee security. There is always the risk of security breaches, whether it's through phishing attacks or employees selling information. The fact that the numbers are published, does relay the information that we have a database possibly containing valuable information.\n",
    "#### (a) Explain how you would protect the data of the people in the training set.  \n",
    "There are a few different ways to do this, but we opted to use the laplace function for differential privacy on the numerical data and just implemented a random choice for the quantitative features. We could also use feature selection by removing columns should they prove to not affect the outcome of the model.   \n",
    "#### (b) Explain how you would protect the data of the people that apply for new loans.  \n",
    "People applying for new loans (e.g the test set) will go through the same noise algorithms as the people in the training set. \n",
    "#### (c) Implement a private decision making mechanism for (b), 3 and estimate the amount of loss in utility as you change the privacy guarantee.\n",
    "For five runs of the model:  \n",
    "Average utility: 1146573.692159097  \n",
    "Average return on investment: 178.52551597951373  \n",
    "For now the loss in utility is rather small, as the noise we add to the data is insignificant. Using MultinomialNB() gives us some struggles with adding noise to the data as it can't take in negative values. For the final delivery we are conisdering different algorithms to achieve this. One possible solution is to set all negative values to 0, but this might skew the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.\n",
    "#### Choose one concept of fairness\n",
    "For this part we originally chose to look at fairness in regards to foreign workers. However, it turned out that only 37 people out of 1000 in our dataset was foreign workers, 34 of which had repaid their initial loan. Because the number of foreign workers was so low, we decided to go for gender equality as suggested in the assignment.  \n",
    "The first thing we did was to look at the data: \n",
    "\n",
    "| Gender | Amount | Repaid | Percentage | \n",
    "|:-------|:-------|:-------|:-----------| \n",
    "| Female | 310    | 201    | 64.8%      | \n",
    "| Male   | 690    | 499    | 72.3%      | \n",
    "\n",
    "We see that the majority of the dataset consists of males. One thing we also took note of was that there was 50 people unaccounted for in the code, as they were assigned 'marital status_A91', which is 'single male', but we did not get a column for this when importing the dataset with pandas.  \n",
    "#### How can you measure whether your policy is fair?\n",
    "Creating a truly fair policy is close to impossible. Given that our policy will try to maximize utility, there will always be edge-cases that gets granted a loan when they shouldn't and vice versa. However, there are some ways we can increase the fairness of our policy. We decided to use metriocracy, as our policy needs to maximise utility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
