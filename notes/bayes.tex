
\section{Probability and Bayesian inference}
\only<article>{One of the most important methods in machine learning
  and statistics is that of Bayesian inference.  This is the most
  fundamental method of drawing conclusions from data and explicit
  prior assumptions. In Bayesian inference, prior assumptions are
  represented as a probabilities on a space of hypothesis. Each
  hypothesis is seen as a probabilistic model of all possible data
  that we can see.}

\only<article>{Frequently, we want to draw conclusions from data. However, the conclusions are never solely inferred from data, but also depend on prior assumptions about reality. 


  \begin{example}
    John claims he has psychic powers and can predict a series of coin tosses. We oblige, and throw a coin 8 times.  John predicts 8 out of 8 coin tosses. The probability of him doing so by chance is $2^{-8}$. If he was a medium, as he claims, then his probability of achieving the feat would be $1$. Should we believe John?
  \end{example}


  \begin{example}
    Traces of DNA are found at a murder scene. We perform a DNA test against a database of $10^4$ citizens registered to be living in the area. We know that the probability of a false positive (that is, the test finding a match by mistake) is $10^{-6}$. If there is a match in the database, does that mean that the citizen was at the scene of the crime?
  \end{example}

  Answering these questions requires us to clearly define what are the possible hypotheses we wish to consider. Taking the first example, we can define two:
  \begin{enumerate}
  \item hypothesis $\model_1$, that John is a medium.
  \item hypothesis $\model_0$, that John is not a medium.
  \end{enumerate}
  We can also define a probability model for the number of successful predictions that John would make in either case. 

  Let $x_t$ be $0$ if John makes an incorrect prediction at time $t$ and $x_t = 1$ if he makes a correct prediction. John's claim that he can predict our tosses perfectly means that for a sequence of tosses $\bx = x_1, \ldots, x_n$,
  \[
  \Pr(\bx \mid \model_1) = \begin{cases}
    1, & x_t = 1 \forall t \in [n]\\
    0, & \exists t \in [n] : x_t = 0.
  \end{cases}
  \]
  That is, the probability of perfectly correct predictions is 1, and that of one or more incorrect prediction is 0. For the other model, we can assume that all draws are independently and identically distributed from a fair coin. Consequently, no matter what John's predictions are, we have that:
  \[
  \Pr(\bx \mid \model_0) = 2^{-n}.
  \]
  So, for the given example, as stated, we have the following facts:
  \begin{itemize}
  \item If John makes one or more mistakes, then $\Pr(\bx \mid \model_1) = 0$ and $\Pr(\bx \mid \model_0) = 2^{-n}$. Thus, we should perhaps say that then John is not a medium
  \item If John makes no mistakes at all, then 
    \begin{align}
      \Pr(\bx \mid \model_1) &= 1,
      &
        \Pr(\bx \mid \model_0) &= 2^{-n}.
    \end{align}
  \end{itemize}
  Does that mean that we must conclude that John is a medium? What if
  $n = 1$? What if $n=100$?  In fact, our conclusion should somehow
  depend on the strength of the evidence. Should it also not depend on how
  likely we think that a medium exists?

  It is this latter idea that we'll try and exploit. We'd like to combine the weight of the evidence, with the weight of our prior beliefs about reality.
  To do this, we first recall the definition of conditional probability. 
}


\subsection{Conditional probability and Bayesian inference}
\only<article>{
  Let $A$ and $B$ be two events. Let $P(A)$ be the probability of event $A$ and $P(B)$ the probability of event $B$. We can think of the probability of an event as the \emph{relative size} of the event in the space of probabilities.\footnote{More formally, probability is a measure; a function similar to volume, area, length and mass.} 
  The probability of both events $A$ and $B$ happening at the same time is denoted by $P(A \cap B)$.  This amounts to measuring the size of the space by the intersection of $A$ and $B$.
  The basic probability laws are the following.
}
\begin{frame}
  \begin{block}{Axioms of probability}
    \begin{enumerate}
    \item The probability of the certain event is $P(\Omega) = 1$
    \item The probability of the impossible event is
      $P(\emptyset) = 0$
    \item The probability of any event $A$ is $1 \leq P(A) \geq 0$.
    \item If $A, B$ are disjoint, i.e. $A \cap B = \emptyset$, meaning
      that they cannot happen at the same time, then
      \[
      P(A \cup B) = P(A) + P(B)
      \]
    \end{enumerate}
  \end{block}
\end{frame}

\begin{frame}
  \only<article>{ Sometimes we would like to calculate the probability
    of some event $A$ happening given that we know that some other
    event $B$ has happened. For this we need to first define the idea
    of conditional probability.  }
  \begin{definition}[Conditional probability]
    The probability of $A$ happening if we know that $B$ has happened
    is defined to be:
    \[
    P(A \mid B) \defn \frac{P(A \cap B) }{P(B)}.
    \]
  \end{definition}
  \only<article>{ Here, the probability measure of any event $A$ given
    $B$ is defined to be the probability of the intersection of of the
    events divided by the second event.  We can rewrite this
    definition as follows, by using the definition for $P(B \mid A)$}
\end{frame}
\begin{frame}
  \begin{block}{Bayes's theorem}
    \[
    P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}.
    \]
  \end{block}
  \only<article>{ Now let us apply this idea to our specific
    problem. This allows us to calculate the probability of John being
    a medium, given the data:
    \[
    \Pr(\model_1 \mid \bx) = \frac{\Pr(\bx \mid \model_1)
      \Pr(\model_1)}{\Pr(\bx)},
    \]
    where
    \[
    \Pr(\bx) = \Pr(\bx \mid \model_1) \Pr(\model_1) + \Pr(\bx \mid
    \model_0) \Pr(\model_0).
    \]
    The only thing left to specify is $\Pr(\model_1)$, the probability
    that John is a medium before seeing the data. This is our
    subjective prior belief that mediums exist and that John is one of
    them.

    More generally, we can think of Bayesian inference as follows:
    \begin{itemize}
    \item We start with a set of mutually exclusive hypotheses
      $H = \{\model_1, \ldots, \model_k\}$.
    \item Each hypothesis $\model$ is represented by a specific
      probabilistic model for any possible data $\bx$, that is
      $\Pr(\bx \mid \model)$.
    \item For each hypothesis, we have a prior probability
      $\Pr(\model)$ that it is correct.
    \item After observing the data, we can calculate a posterior
      probability that the hypothesis is correct:
      \[
      \Pr(\model \mid \bx) = \frac{\Pr(\bx \mid \model)
        \Pr(\model)}{\sum_{i=1}^k \Pr(\bx \mid \model_i)
        \Pr(\model_i)}.
      \]
    \end{itemize}
    Combining the prior belief with evidence is key in this
    procedure. Our posterior belief can then be used as a new prior
    belief when we get more evidence.  }
\end{frame}

\subsection{Naive Bayes classifiers}
\begin{frame}
  \only<article>{ One special case of this idea is in classification,
    when each hypothesis corresponds to a specific class. Then, given
    a new example vector of data $\bx$, we would like to calculate the
    probability of different classes $C$ given the data,
    $\Pr(C \mid \bx)$. So here, the class is the hypothesis.

    From Bayes's theorem, we see that we can write this as }
  \[
  \Pr(C \mid \bx) = \frac{\Pr(\bx \mid C) \Pr(C)}{\sum_{i} \Pr(\bx
    \mid C_i) \Pr(C_i)}
  \]
  \only<article>{ for any class $C$. This directly gives us a method
    for classifying new data, as long as we have a way to obtain
    $\Pr(\bx \mid C)$ and $\Pr(C)$.  }

  But should we use for the probability model $\Pr$?

\begin{block}{Calculating the prior probability of classes}
  A simple method is to simply count the number of times each class
  appears in the training data $\Training = ((x_t,
  y_t))_{t=1}^T$. Then we can set
  \[
  \Pr(C) = 1/T \sum_{t=1}^T \ind{y_t = C}
  \]
\end{block}

\only<article>{ The Naive Bayes classifier uses the following model
  for observations, where observations are independent of each other
  given the class. Thus, for example the result of three different
  tests for lung cancer (stethoscope, radiography and biopsy) only
  depend on whether you have cancer, and not on each other.  }
\begin{block}{Probability model for observations}
  \[
  \Pr(\bx \mid C) = \Pr(x(1), \ldots, x(n) \mid C) = \prod_{k=1}^n
  \Pr(x(k) \mid C).
  \]
\end{block}

\end{frame}

\begin{frame}
  \only<article>{There are two different types of models we can have,
    one of which is mostly useful for continuous attributes and the
    other for discrete attributes.  In the first, we just need to
    count the number of times each feature takes different values in
    different classes.  }
  \begin{block}{Discrete attribute model.}
    \only<article>{Here we simply count the average number of times
      that the attribute $k$ had the value $i$ when the label was
      $C$. This is in fact analogous to the conditional probability
      definition.}
    \[
    \Pr(x(k) = i \mid C) = \frac{\sum_{t=1}^T \ind{x_t(k) = i \wedge
        y_t = C}} {\sum_{t=1}^T \ind{y_t = C}} = \frac{N_k(i,
      C)}{N(C)},
    \]
    where $N_k(i, C)$ is the numb l l .er of examples in class $C$
    whose $k$-th attribute has the value $i$, and $N(C)$ is the number
    of examples in class $C$.
  \end{block}

  \only<article>{ Sometimes we need to be able to deal with cases
    where there are no examples at all of one class. In that case,
    that class would have probability zero. To get around this
    problem, we add ``fake observations'' to our data. This is called
    \emph{Laplace smoothing}.
    \begin{remark} In Laplace smoothing with constant $\lambda$, our
      probability model is
      \[
      \Pr(x(k) = i \mid C) = \frac{\sum_{t=1}^T \ind{x_t(k) = i \wedge
          y_t = C} + \lambda} {\sum_{t=1}^T \ind{y_t = C} + n_k
        \lambda} = \frac{N_k(i, C) + \lambda}{N(C) + n_k \lambda}.
      \]
      where $n_k$ is the number of values that the $k$-th attribute
      can take. This is necessary, because we want
      $\sum_{i=1}^{n_k} \Pr(x(k) = i \mid C) = 1$. (You can check that
      this is indeed the case as a simple exercise).
    \end{remark}

  \begin{remark}
    In fact, the Laplace smoothing model corresponds to a so-called
    Dirichelt prior over polynomial parameters with a marginal
    probability of observation equal to the Laplace smoothing. We
    shall see more of this in the Bayesian inference section.
  \end{remark}
}
\end{frame}


\begin{frame}
  \begin{block}{Continuous attribute model.}
    \only<article>{Here we can use a Gaussian model for each
      continuous dimension.}
    \[
    \Pr(x(k) = v \mid C) = \frac{1}{\sigma \sqrt{2 \pi}} e^{\frac{(v -
        \mu)^2}{\sigma^2}},
    \]
    where $\mu$ and $\sigma$ are the mean and variance of the
    Gaussian, typically calculated from the training data as:
    \begin{align*}
      \mu &=   \frac{\sum_{t=1}^T x_t(k) \ind{y_t = C}}
            {\sum_{t=1}^T \ind{y_t = C}},
    \end{align*}
    i.e. $\mu$ is the mean of the $k$-th attribute when the label is
    $C$ and
    \begin{align*}
      \sigma &=   \frac{\sum_{t=1}^T [x_t(k) - \mu]^2 \ind{y_t = C}}
               {\sum_{t=1}^T \ind{y_t = C}},
    \end{align*}
    i.e. $\sigma$ is the variance of the $k$-th attribute when the
    label is $C$.  Sometimes we can just fix $\sigma$ to a constant
    value, i.e. $\sigma = 1$.
  \end{block}
\end{frame}

\begin{frame}
  \begin{alertblock}{Estimates versus true probabilities}
    Remember that the probabilities we get from this calculation are
    only \alert{estimates}. We do not really know the probabilities of
    each observation given the classes: we are only estimating them
    from the data. It is also possible that our assumption about the
    independence of features is completely wrong.
  \end{alertblock}
\end{frame}

\subsection{Full Bayesian inference}
\only<article>{Statistical inference is the problem estimating quantities from data. Many machine learning problems lie within the statistical inference framework. While there are many paradigms within this framework, one typically tries to calculate probability distributions of some random variables from data. These are usually expressed in terms of parametrised distributions. In the Bayesian setting in particular, the goal is to quantify our uncertainty about these unknown parameters in terms of another probability distribution.}
\begin{frame}
  \frametitle{Bayesian inference} \only<article>{ Bayesian statistical
    inference is the problem of inferring distributions (of
    parameters) from data. Typically, given some prior distribution
    $\bel(\model)$ on parameters $\model \in \Model$, such that for
    every possible parameter value the probability $P_\model(x)$ is
    well defined for any $x \in \CX$, we wish to infer a posterior
    distribution from any given data $x$.}
  \begin{definition}[Posterior distribution]
    \only<article>{Given a prior $\bel$ on the parameter set $\Model$
      and a family $\{P_\model\}$ of distributions on $\CX$, the
      posterior distribution of parameter $\model$ for any data
      $x \in \CX$ is}
    \begin{equation}
      \bel(\model \mid x) \defn \frac{P_\model(x) \bel(\model)}{\sum_{\model' \in \Model}
        P_{\model'}(x) \bel(\model')}.
      \label{eq:posterior}
    \end{equation}
  \end{definition}
\end{frame}






%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "notes.tex"
%%% End:
