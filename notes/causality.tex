\section{Introduction}
\only<presentation>{
  \begin{frame}
    \tableofcontents[ 
    currentsection, 
    hideothersubsections, 
    sectionstyle=show/shaded
    ] 
  \end{frame}
}

\begin{frame}
  \frametitle{Headaches and aspirins}
  \only<article>{Causal questions do not just deal with statistical relationships. The meaning of these questions is slightly different depending on whether we are talking about the population at large, or a specific individual. For populations, the main question is whether or not our actions have a causal effect. In observational data, we also need to consider the \emph{direction of causation}.}
  \begin{example}[Population effects]
    \only<article>{
      We can ask ourselves two different questions about the effect of population effect aspirin on headaches.
    }
    \begin{itemize}
    \item Is aspirin an effective cure for headaches?
    \item Does having a headache lead to aspirin-taking?
    \end{itemize}
  \end{example}
  \only<article>{For individuals, the first question is,  what is the possible effect of our actions? This is called the \emph{effect of causes}. The second question is, what was the reason for something happening? That is called the \emph{cause of effects?} }
  \begin{example}[Individual effects]
    \only<article>{
      We can ask ourselves two different questions about the individual effect of aspirin on headaches.
    }
    \begin{itemize}
    \item Effects of \alert{Causes}: Will my headache pass if I take an \alert{aspirin}?
    \item \alert{Causes} of Effects: Would my headache have passed if I had not taken an \alert{aspirin}?
    \end{itemize}
  \end{example}
  \only<article>{In order to be able to meaningfully talk about effects and causes we must also introduce decisions. Formally, there is nothing different in the decisions in this section and those introduced in Section~\ref{sec:decision-problems}. However, in this case we will try and use decisions to model outside interventions in a ``natural'' system, whereby a \emph{null} decision means that we do not intervene.}
\end{frame}
\subsection{Decision diagrams}
\only<article>{
  Graphical models can also be used to model causal relations. In particular, we can use \emph{decision diagrams}\footnote{Otherwise called influence diagrams}, which include not only random variables, but also \emph{decision} variables, denoted with squares, as well as utility variables, denoted via diamonds. In the following examples, we assume there are some underlying distributions specified by parameters $\param$, which we include in the diagrams for clarity. Even though it may seem intuitively sensible to suppose it, the arrow directions in the diagrams \emph{do not} indicate direct causes. The only important thing for determining whether some variable influences another is whether or not there is independence between the corresponding decision and random variables.}
\begin{frame}
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \node[RV, hidden] at (-1,1) (p) {$\param$};
      \node[RV] at (0,0) (x) {$x_t$};
      \node[RV] at (1,1) (y) {$y_t$};
      \only<1,2>{
        \node[select] at (2,0) (a) {$a_t$};
      }
      \only<3->{
        \node[RV] at (2,0) (a) {$a_t$};
      }
      \draw[->] (x)--(y);
      \draw[->] (x)--(a);
      \draw[->] (a)--(y);
      \draw[->] (p) to (x);
      \draw[->] (p)--(y);
      \onslide<3->{
        \node[select] at (4,0) (pol) {$\pol$};
        \draw[->] (pol)--(a);
      }
      \onslide<2->{
        \node[utility] at (3,1) (u) {$\util$};
        \draw[->] (a)--(u);
        \draw[->] (y)--(u);
      }
    \end{tikzpicture}
    \caption{A typical decision diagram where $x_t$: individual information, $y_t$: individual result, $a_t$: action, $\pol$: policy}
    \label{fig:decision-diagram}
  \end{figure}
  \only<3>{
    \begin{example}[Taking an aspiring]
      \only<article>{The diagram in Figure~\ref{fig:decision-diagram} does not completely specify the decision problem. For aspirin taking, we can define the following variables:}
      \begin{itemize}
      \item Individual $t$
      \item Information $x_t$
      \item $a_t  = 1$ if $t$ takes an aspirin, and $0$ otherwise.
      \item $y_t = 1$ if the headache is cured in 30 minutes, $0$ otherwise.
      \item $\pol$: intervention policy.
      \end{itemize}
    \end{example}
  }
  \only<4>{
    \begin{example}[A recommendation system]
      \only<article>{Consider the example of a recommendation system, where we have data of the form $(x_t, a_t, y_t)$. The performance of the recommendation system depends not only on the parameter $\param$, but also on the chosen policy $\pol$. }
      \begin{itemize}
      \item $x_t$: User information (random variable)
      \item $a_t$: System action (random variable)
      \item $y_t$: Click (random varaible)
      \item $\pol$: recommendation policy (decision variable).
      \end{itemize}
    \end{example}
  }
  \only<article>{In both cases, there are some questions we can ask using the underlying model. The dependency structure is not enough to know \emph{a priori} whether we can obtain meaningful answers. This depends on the specific assumptions we make about the model.}
\end{frame}

\begin{frame}
  \frametitle{Conditional distributions and decision variables.}
  \only<article>{We begin with a parenthesis on conditional distributions. We normally define the conditional distribution of $A$ given $B$ under a probability measure $P$ as:}
  \[
  P(A \mid B) \defn \frac{P(A \cap B)}{P(B)}.
  \]
  \only<article>{However, decision variables are outside the scope of this probability measure, and yet we need to define conditional distributions using them. }
  \begin{block}{The conditional distribution of decisions}
    \only<article>{If $\pol \in \Pol$ is a decision variable, we represent the conditional distribution of any random variable $a$ given $\pol$ simply as a collection of probability measures $\cset{\pol(a)}{\pol \in \Pol}$, one for each possible value $\pol$. The following notations will be equivalent:}
    \[
    \pol(a) \equiv \Pr^\pol(a) \equiv \Pr(a \mid \pol).
    \]
    \only<article>{The reader should note that the standard definition of a conditional distribution also $P(A \mid B)$ creates a collection of distributions on $A$, with elements $P_B(A)$. However, it also specifies a rule for doing so from the complete distribution $P$. 

      If the random variables $a$ also depends on some probability law $P_\param$, then it will be convenient to use the notation
    }
    \[
    \Pr_\param^\pol(a) \equiv \Pr(a \mid \param, \pol).
    \]
  \end{block}
\end{frame}
\subsection{Common structural assumptions}
\only<article>{
  In order to be clear about what constitutes an observation by the experimenter and what is a decision, we must clearly separate random variables from decision variables. The individual actions may be random variables, but they will depend on decisions taken. As we will see later, this is useful for modelling interventions.}

\begin{frame}
  \frametitle{Basic causal structures}
  \only<article>{Directed graphical models are not sufficient to determine causality by themselves, as they only determine correlations between random variables. If we have decision variables, however, we can always determine whether or not our decisions influence outcomes.}
  \begin{block}{Non-cause}
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \node[select] at (0,0) (p) {$\pol$};
        \node[RV] at (1,0) (a) {$a_t$};
        \node[RV] at (2,0) (y) {$y_t$};
        \draw[->] (p) to (a);
        \draw[->] (y) to (a);
      \end{tikzpicture}
      \caption{$\pol$ does not cause $y$}
      \label{fig:non-cause}
    \end{figure}
    \only<article>{In the diagram above, we see that $y_t \indep \pol$.}
  \end{block}
  \only<article>{
    \begin{example}
      Consider the model
      \begin{align*}
        y_t &\sim \Normal(0,1)\\
        a_t \mid y_t, \pol &\sim \Normal(y_t + \pol, 1)
      \end{align*}
      \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\textwidth]{../src/causality/non-cause}
        \caption{$\Pr^\pol(y_t)$ for $\pol \in \{-1, 1\}$ when $\pol$ is not a cause for $y_t$}
        \label{fig:non-cause-dist}
      \end{figure}
      In this example, we see tht $y_t$ is independent of the policy
      $\pol$.  However, $y_t$ is not independent of the action taken, as the action depends on $y_t$ directly. The correlation between $y, a$ is shown in Figure~\ref{fig:a-y-correlation:non-cause}.
    \end{example}
  }
  
  \begin{block}{No confounding}
    \only<article>{Confounding is a term that indicates the existence of latent variables that create dependencies between $y_t, \pol, a_t$. We are sure that there is no confounding whenever $y_t \indep \pol \mid a_t$, as captured by the diagram in Figure~\ref{fig:no-confounding}. In this case $\pol$ is a direct cause for $y_t$ through $a_t$.}
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \node[select] at (0,0) (p) {$\pol$};
        \node[RV] at (1,0) (a) {$a_t$};
        \node[RV] at (2,0) (y) {$y_t$};
        \draw[->] (p) to (a);
        \draw[->] (a) to (y);
      \end{tikzpicture}
      \caption{No confounding: $\pol$ causes $y_t$}
      \label{fig:no-confounding}
    \end{figure}
  \end{block}

  \only<article>{
    \begin{example}
      Consider the model
      \begin{align*}
        a_t &\sim \Normal(\pol,1)\\
        y_t \mid a_t, \pol &\sim \Normal(a_t, 1)
      \end{align*}
      \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\textwidth]{../src/causality/direct-cause}
        \caption{$\Pr^\pol(y_t)$ for $\pol \in \{-1, 1\}$ when $\pol$ is a direct cause for $y_t$}
        \label{fig:non-cause-dist}
      \end{figure}
      \only<article>{We can see how the distribution of $y_t$ changes when $\pol$ changes in Figure~\ref{fig:non-cause-dist}. In this case there is also a correlation between $a_t, y_t$ as seen in Figure~\ref{fig:a-y-correlation}.}
    \end{example}
  }

  \only<article>{
    \begin{figure}[H]
      \centering
      \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=0.9\textwidth]{../src/causality/a-y-non-cause}
        \caption{Non-cause}
        \label{fig:a-y-correlation:non-cause}
      \end{subfigure}
      \hspace{1em}
      \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=0.9\textwidth]{../src/causality/a-y-direct-cause}
        \caption{Cause}
        \label{fig:a-y-correlation:cause}
      \end{subfigure}
      \caption{Correlation between $a_t$ and $y_t$}
      \label{fig:a-y-correlation}
    \end{figure}
  }
\end{frame}
\begin{frame}
  \frametitle{Covariates}
  \begin{block}{Sufficient covariate}
    \only<article>{Sometimes the variable of interest is not conditionally independent of the treatment, unless there exists a \emph{sufficient covariate} $x_t$ such that
      $y_t \indep \pol \mid a_t, x_t$. If $x_t$ is not observed, then it is sometimes called a confounder.}
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \node[select] at (0,0) (p) {$\pol$};
        \node[RV] at (1,0) (a) {$a_t$};
        \node[RV] at (2,0) (y) {$y_t$};
        \node[RV] at (2,1) (x) {$x_t$};
        \draw[->] (p) to (a);
        \draw[->] (a) to (y);
        \draw[->] (x) to (a);
        \draw[->] (x) to (y);
      \end{tikzpicture}
      \caption{Sufficient covariate $x_t$}
      \label{fig:sufficient-covariate}
    \end{figure}
  \end{block}

  \only<article>{
    \begin{example}
      Consider the model
      \begin{align*}
        x_t &\sim \Normal(0, 1)\\
        a_t &\sim \Normal(x_t + \pol, 1)\\
        y_t \mid a_t, \pol &\sim \Normal(x_t + a_t, 1),
      \end{align*}
      \only<article>{Here $x_t$ influences the outcome $y_t$, but also directly influences $a_t$ through the policy $\pol$. As we can see in Figure~\ref{fig:non-cause-dist}, the policy then has an influence on $y_t$}
      \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\textwidth]{../src/causality/sufficient}
        \caption{$\Pr^\pol(y_t)$ for $\pol \in \{-1, 1\}$ when $\pol$ is a direct cause for $y_t$}
        \label{fig:sufficient-covariate-dist}
      \end{figure}
    \end{example}
  }


  \begin{block}{Instrumental variables and confounders}
    \only<article>{If the sufficient covariate $x_t$ is not observed, we may still have another variable available, $z_t$, which depends on $x_t$, which is observed, and on the basis of which we make our decisions. However the effect of the treatment depends on $x_t$ directly. This is called an \emph{instrumental variable.} \index{instrument@see{variable, instrumental}}\index{variable,instrumental} As $x_t$ is a latent covariate, it can be called a \emph{confounder.} \index{confounder}}
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \node[select] at (0,0) (p) {$\pol$};
        \node[RV] at (1,0) (a) {$a_t$};
        \node[RV] at (2,0) (y) {$y_t$};
        \node[RV, hidden] at (2,1) (x) {$x_t$};
        \node[RV] at (1,1) (z) {$z_t$};
        \draw[->] (p) to (a);
        \draw[->] (a) to (y);
        \draw[->] (x) to (y);
        \draw[->] (x) to (z);
        \draw[->] (z) to (a);
      \end{tikzpicture}
      \caption{Instrumental variable $z_t$}
      \label{fig:instrumental-variable}
    \end{figure}
  \end{block}

  \only<article>{
    \begin{example}
      Consider the model
      \begin{align*}
        x_t &\sim \Normal(0, 1)\\
        z_t &\sim \Normal(x_t, 1)\\
        a_t &\sim \Normal(z_t + \pol, 1)\\
        y_t \mid a_t, \pol &\sim \Normal(x_t + a_t, 1)
      \end{align*}
      \only<article>{In this scenario, $x_t$ directly influences the outcome $y_t$, but is not observed.\footnote{Hence, it can be called a confounder.}}
      \begin{figure}[H]
        \centering
        \includegraphics[width=0.5\textwidth]{../src/causality/instrumental}
        \caption{$\Pr^\pol(y_t)$ for $\pol \in \{-1, 1\}$ when $\pol$ is a direct cause for $y_t$}
        \label{fig:instrumental-dist}
      \end{figure}
    \end{example}
  }


\end{frame}


\section{Interventions}
\only<article>{Interventions are of primary interest when we have a set of observational data, collected under a \emph{null} or \emph{default} policy $\pol_0$.  We then wish to intervene with some policy $\pol$ in order to maximise our utility function, or to simply try and estimate the exact relationships between variables.}
\begin{frame}
  \begin{example}[Weight loss]
    \only<article>{Consider weight loss. We can collect observational data from a population of overweight adults over a year. We can imagine that $x$ represents the weight and vital statistics of an individual and $y$ their change in weight after a year. We may also observe their individual actions $a$, such as whether or not they are following a particular diet or exercise regime. Under the default policy $\pol_0$, their actions are determined only the individuals. Consider an alternative policy $\pol$, which prescribes diet and exercise regimes. Due to non-compliance, actual actions taken by individuals may differ from prescribed actions.}
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \node[RV] at (0,0) (x) {$x$};
        \node[RV] at (1,1) (y) {$y$};
        \node[RV] at (2,0) (a) {$a$};
        \draw[->] (x)--(y);
        \draw[->] (x)--(a);
        \draw[->] (a)--(y);
        \node[select] at (4,0) (p) {$\pol$};
        \draw[->] (p)--(a);
        \node[utility] at (3,1) (u) {$\util$};
        \draw[->] (a)--(u);
        \draw[->] (y)--(u);
      \end{tikzpicture}
    \end{figure}
  \end{example}
\end{frame}  


\subsection{Learning instrumental variables}
\begin{frame}
  \begin{example}[Pricing model]
    \only<article>{In the following pricing model, we wish to maximise profits for an airline}
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \node[RV] at (0,0) (x) {$x_t$};
        \node[RV] at (1,0) (y) {$y_t$};
        \node[RV] at (0,1) (z) {$z_t$};
        \node[RV] at (1,1) (p) {$a_t$};
        \node[select,hidden] at (2,1) (pol) {$\pol$};
        \node[RV,hidden] at (2,0) (o) {$\omega_t$};
        \draw[->] (x) to (y);
        \draw[->] (x) to (p);
        \draw[->] (z) to (p);
        \draw[->] (p) to (y);
        \draw[->] (o) to (p);
        \draw[->] (o) to (y);
        \draw[->] (pol) to (p);
      \end{tikzpicture}
      \caption{$a_t$ is the price, $z_t$ are fuel costs, $x_t$ is the customer type, $y_t$ is the amount of sales, $\omega_t$ is whether there is a conference.}
    \end{figure}
    \begin{equation}
      \label{eq:price}
      y_t = g_\param(a_t, x_t) + \omega_t, \qquad \E_\param \omega_t = 0, \qquad \forall \param \in \Param
    \end{equation}
  \end{example}
  \begin{block}{Standard prediction}
    \only<article>{In standard prediction tasks, we just want to estimate the distribution of sales given the characteristics and price. Since the actions are correlated with the outcome through the confounder, this estimate is biased.}
    \[
    \Pr_\param^\pol(y_t \mid x_t, a_t), \qquad  \E^\pol_\param(y_t \mid x_t, a_t) = g_\param(x_t, a_t) + \E_\param^\pol(\omega_t \mid x_t, a_t).
    \]
  \end{block}
  \begin{assumption}[Relevance]
    $a_t$ depends on both $x_t, z_t$.
  \end{assumption}
  \begin{assumption}[Exclusion]
    $z_t \indep y_t \mid x_t, a_t, \omega_t$.
  \end{assumption}
  \begin{assumption}[Unconfounded instrument]
    $z_t \indep \omega_t \mid x_t$.
  \end{assumption}
\end{frame}

\begin{frame}
  \only<article>{Let us define the function}
  \begin{block}{Counterfactual prediction function}
    \only<article>{Let us restrict our policies to those that only depend on $x_t$. Then any $\pol, x_t$ pair defines a unique action $a_t$.}
    \[
    h(\pol, x_t) \defn \E_\param(y_t \mid \pol, x_t) =  g_\param(\pol, x_t) + \E_\param(\omega_t \mid x_t)
    \]
  \end{block}
  \[
  \E^\pol_\param(y_t \mid x_t, z_t) = \E^\pol_\param(g \mid x_t, z_t) + \E_\param(\omega_t \mid x_t)
  = \int h(p, x) \dd{\pol}(a_t \mid x_t, z_t)
  \]
\end{frame}
\subsection{Confounders}
\begin{frame}
  \begin{example}[Weight loss]
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \node[RV] at (0,0) (x) {$x$};
        \node[RV] at (1,1) (y) {$y$};
        \node[RV] at (2,0) (a) {$a$};
        \draw[->] (x)--(y);
        \draw[->] (x)--(a);
        \draw[->] (a)--(y);
        \node[select] at (4,0) (p) {$\pol$};
        \draw[->] (p)--(a);
        \node[utility] at (3,1) (u) {$\util$};
        \draw[->] (a)--(u);
        \draw[->] (y)--(u);
        \node[RV, hidden] at (0,2) (c) {$c$};
        \draw[->] (c)--(y);
      \end{tikzpicture}
    \end{figure}
  \end{example}
\end{frame}  

\subsection{Inference in causal models}

\only<article>{Inference in causal models requires building a complete model for the effect of every action.}

\section{Counterfactuals}

\only<article>{
  Counterfactual analysis is mainly about questions relative to individuals, and specifically about what the effects of alternative actions would have been in the past. 
}
\subsection{Disturbances and structural equation models}

\begin{frame}
  \only<article>{A structural equation model describes the random variables as deterministic functions of the decisions variables and the random exogenous disturbances. This allows us to separate the unobserved randomness from the known functional relationship between the other variables. Structurally, the model is essentially a variant of decision diagrams, as shown in Figure~\ref{fig:disturbance-model}.}
  \begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \node[RV, hidden] at (-1,1) (p) {$\param$};
      \node[RV] at (0,0) (x) {$x_t$};
      \node[RV] at (1,1) (y) {$y_t$};
      \node[RV] at (2,0) (a) {$a_t$};
      \draw[->] (x)--(y);
      \draw[->] (x)--(a);
      \draw[->] (a)--(y);
      \draw[->] (p) to (x);
      \draw[->] (p)--(y);
      \node[select] at (4,0) (pol) {$\pol$};
      \draw[->] (pol)--(a);
      \node[utility] at (3,1) (u) {$\util$};
      \draw[->] (a)--(u);
      \draw[->] (y)--(u);
      \node[RV, hidden, above of=y]  (oy) {$\omega_{t,y}$};
      \node[RV, hidden, below of=x]  (ox) {$\omega_{t,x}$};
      \node[RV, hidden, below of=a]  (oa) {$\omega_{t,a}$};
      \draw[->] (ox) -- (x);
      \draw[->] (oa) -- (a);
      \draw[->] (oy) -- (y);
    \end{tikzpicture}
    \caption{Decision diagram with exogenous disturbances $\omega$.}
    \label{fig:disturbance-model}
  \end{figure}
  \only<article>{We still need to specify particular functional relationships between the variables. Generally speaking, a random variable taking values in $\CX$, is simply a function $\Omega \times \Param \to \CX$. For example, in Figure~\ref{fig:disturbance-model} $y_t = f_y(\omega, \theta)$. Taking into account the dependencies, this can be rewritten in terms of a function of the other random variables, and the local disturbance: $y_t = f_{y|a,x}(a,x, \omega_{t,y}, \theta)$. The choice of the function, together with the distribution of the parameter $\param$ and the disturbances $\omega$, fully determines our model.}
  \begin{example}[Structural equation model  for Figure~\ref{fig:disturbance-model}]
    \only<presentation>{\vspace{-1em}}
    \only<article>{
      In structural equation models, the only random variables are the exogenous disturbances. In a fully Bayesian framework, $\param$ is also a latent random variable. The remaining variables are  deterministic functions. 
    }
    \begin{align*}
      \theta &\sim \Normal(\vectorsym{0}_4, \eye_4),\\
      x_t &= \theta_0 \omega_{t,x},
          & \omega_{t,x} &\sim \Bernoulli(0.5)\\
      y_t &= \theta_1 y_t + \theta_2 x_t + \theta_3 a_t + \omega_{t,y},
          &\omega_{t,y} &\sim \Normal(0,1)\\
      a_t &= \pol(x_t) + \omega_{t,a} \mod |\CA| 
          &\omega_{t,a} &\sim 0.1 \Singular(0) + 0.9 \Uniform(\CA),
    \end{align*}
  \end{example}
  \only<article>{Structural equation models are particularly interesting in applications such as economics, where there are postulated relations between various economic quantities. }
\end{frame}

\begin{frame}
  \frametitle{Treatment-unit additivity}
  
\end{frame}



\section{Application to recommendation systems}
\begin{frame}

  \only<2>{
    \only<article>{If we have data $D = \cset{(x_t, a_t, y_t)}{t \in [T]}$ generated from some policy $\pol_0$, we can always infer the average quality of each action $a$ under that policy.}
    \begin{align}
      \label{eq:observed-expected-utility}
      \hat{\E}_D(U \mid a) 
      &\defn
        \frac{1}{|\cset{t}{a_t = a}|}
        \sum_{t: a_t = a}
        U(a_t, y_t)
        \approx
        \E^{\pol_0}_\param (U \mid a).
    \end{align}
  }
  \only<article>{
    Can we calculate the value of another policy? As we have seen from Simpson's paradox\index{Simpson's paradox}, it is folly to simply select
    \[
    \hat{a}^*_D \in \argmax_a \hat{\E}_D(U \mid a),
    \]
    as the action also depends on the observations $x$ through the policy.
    To clarify this, let us define the model shown in Figure~\ref{fig:recommendation-decision-diagram}.
    \begin{align*}
      x_t \mid \param, x_t &\sim P_\param(x)\\
      y_t \mid \param, x_t, a_t &\sim P_\param(y \mid x_t, a_t)\\
      a_t \mid x_t, \pol &\sim \pol(a \mid x_t).
    \end{align*}
    Assume that $x \in \CX$, a continuous space, but $y \in \CY$ is discrete. Then the value of an action under a policy $\pol$ is
    \begin{align*}
      \E^\pol_\param(\util \mid a)
      &=
        \int_\CX \dd P_\param(x)
        \sum_{y \in \CY} P_\param(y \mid x, a) \util(a, y).
    \end{align*}
    We see that there is a clear dependence on the distribution of $x$, and there is no dependence on the policy any more. In fact, equation above only tells us the expected utility we'd get if we always chose the same action $a$. But what is the optimal policy? First, we have to define the value of a policy.
  }
  
  \begin{block}{The value of a policy}
    \begin{align*}
      \E^\pol_\param(\util)
      &=
        \int_\CX \dd P_\param(x)
        \sum_{y \in \CY} P_\param(y \mid x, a) \util(a, y) \sum_{a \in \CA} \pol(a \mid x).
    \end{align*}
  \end{block}
  \only<article>{
    The optimal policy under a known parameter $\param$ is given simply by
    \begin{align*}
      \max_{\pol \in \Pol} \E^\pol_\param(\util),
    \end{align*}
    where $\Pol$ is the set of allowed policies. How can we actually find the optimal policy?
  }
\end{frame}


\subsection{Discussion}
\begin{frame}
  \begin{block}{Further reading}
    \begin{itemize}
    \item Pearl, \emph{Causality}.
    \item \citet{dawid2012decision}
    \end{itemize}
  \end{block}
\end{frame}
%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "notes"
%%% End:
