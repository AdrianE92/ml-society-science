\chapter{Simple decision problems}

\only<article>{This chapter deals with simple decision problems, whereby a decision maker (DM) makes a simple choice among many. In some of this problems the DM has to make a decision after first observing some side-information. Then the DM uses a \emph{decision rule} to assign a probability to each possible decision for each possible side-information. However, designing the decision rule is not trivial , as it relies on previously collected data. A higher-level decision includes choosing the decision rule itself. The problems of classification and regression fall within this framework. While most steps in the process can be automated and formalised, a lot of decisions are actual design choices made by humans. This creates scope for errors and misinterpretation of results.

In this chapter, we shall formalise all these simple decision problems from the point of view of statistical decision theory. The first question is, given a real world application, what type of decision problem does it map to? Then, what kind of machine learning algorithms can we use to solve it? What are the underlying assumptions and how valid are our conclusions? Does application of the method have a societal impact? In particular, is there scope for privacy violations, reinforcing racial biases or creating other negative externalities?
}
\section{Introduction to machine learning}
 

\only<article>{
 What are the central problems in machine learning?

 Problems in machine learning are similar to problems in science.
 Scientists must plan experiments intelligently and collect data.
 The must be able to use the data to verify a different hypothesis.
 More generally, they must be able to make decisions under
 uncertainty (Without uncertainty, there would be no need to gather more data).
 Similar problems appear in more mundane tasks, like learning to drive a car.
}
\only<presentation>{
 \begin{frame}
   \frametitle{Scientific applications}
   \centering
   \begin{columns}
     \begin{column}{0.5\textwidth}
       \centering
       \includegraphics[width=0.8\columnwidth]{../figures/climate.jpg}\\
       \includegraphics[width=\columnwidth]{../figures/networks-2.jpg}
     \end{column}
     \begin{column}{0.5\textwidth}
       \includegraphics[width=\columnwidth]{../figures/dark_matter.jpg}
       \\
       \includegraphics[width=\columnwidth]{../figures/protein.jpg}
     \end{column}
   \end{columns}
  \only<2>{
    \begin{tikzpicture}[remember picture,overlay]
      \draw[fill=black,opacity=0.75] 
      (current page.north east) rectangle (current page.south west);
      \node at (current page.center) {
        {\Huge \alert{Interpretability, Reproducibility}}
      };
    \end{tikzpicture}}
\end{frame}
}

\only<article>{
 For that reason, science is a very natural application area for
 machine learning.  We can model the effects of climate change and
 how to mitigate it; discover structure in social networks; map
 the existence of dark matter in the universe by intelligently
 shifting through weak gravitational lens data, and not only study
 the mechanisms of protein folding, but discover methods to
 synthesize new drugs.

 We must be careful, however. In many cases we need to be able to
 interpret what our model tells us. We also must make sure that
 the any results we obtain are reproducible. This is something
 that we shall emphasize in this course.
}

\only<presentation>{
\begin{frame}
  \frametitle{Pervasive ``intelligent'' systems}
  \begin{columns}
    \begin{column}{0.3\textwidth}
      \centering
      \includegraphics[width=\textwidth]{../figures/echo-home.jpg}
      \\
      Home assistants

      \vspace{\fill}

      \bigskip

      \includegraphics[width=\textwidth]{../figures/tesla.jpg}
      \\
      Autonomous vehicles
    \end{column}
    \begin{column}{0.3\textwidth}
      \centering 
      \includegraphics[width=\textwidth]{../figures/web-ads.png}
      \\
      Web advertising

      \vspace{\fill}

      \bigskip

      \includegraphics[width=\textwidth]{../figures/uber-here-maps.jpg}
      \\
      Ridesharing
    \end{column}
    \begin{column}{0.3\textwidth}
      \centering 
      \\
      \includegraphics[width=\textwidth,clip = true, trim=0 0 0 42.5cm]{../figures/lending.pdf}
      \\
      Lending

      \vspace{\fill}

      \bigskip

      \includegraphics[width=\textwidth]{../figures/algorithms-public.jpg}
      \\
      Public policy
    \end{column}
  \end{columns}
  \only<2>{
    \begin{tikzpicture}[remember picture,overlay]
      \draw[fill=black,opacity=0.75] 
      (current page.north east) rectangle (current page.south west);
      \node at (current page.center) {
        {\Huge \alert{Privacy, Fairness, Safety}}
      };
    \end{tikzpicture}}
\end{frame}
}

\only<article>{
 While machine learning models in science are typically carefully
 handcrafted by scientists and experts in machine learning and
 statistics, this is not typically the case in everyday
 applications. Nevertheless, well-known or home-grown machine
 learning models are being deployed across the application
 spectrum. This involve home assistants that try and get you want,
 web advertising, which tries to find new things for you to want,
 lending, which tries to optimally lend you money so that you buy
 what you didn't need before. We also have autonomous vehicles,
 which take you were you want to go, and ridesharing services,
 which do the same thing, but use humans instead. Finally, there
 are many applications in public policy, such as crime prevention,
 justice, and disease control which use machine learning.  In all
 those cases, we have to worry about a great many things that are
 outside the scope of the machine learning problems itself. These
 are (a) privacy: you don't want your data used in ways that you have
 not consented to (b) fairness: you don't want minorities to be
 disadvantaged and (c) safety: you don't want your car to crash.
}

\subsection{Data analysis}

\only<article>{
  To make the above more concrete, let's have a look at a number of problems. 
}

\only<presentation>{
\begin{frame}
  \centering
  \Huge{What can machine learning do?}
\end{frame}
}
\begin{frame}
  \frametitle{Can machines learn from data?}
  \begin{center}
    \only<1>{\includegraphics[width=0.8\textwidth]{../figures/text-cloud}
      \\

      {\large An unsupervised learning problem: topic modelling}
    }
    \only<2>{\includegraphics[width=0.8\textwidth]{../figures/Face-Recognition}
      \\

      {\large A supervised learning problem: object recognition}
    }
  \end{center}
\end{frame}


\only<article>{
You can use machine learning just to analyse, or find structure in
the data. This is generally called unsupervised learning. One such
example is topic modelling, where you let the algorithm find topics
from a corpus of text.  These days machines are used to learn from
in many applications.  These include speech recognition, facial
authentication, weather prediction, etc. In general, in these
problems we are given a \emph{labelled} dataset with, say, example
images from each class. Unfortunately this does not scale very
well, because obtaining labels is expensive.

This is partially how science works, because what we need to do
is to find a general rule of nature from data. Starting from some
hypothesis and some data, we reach a conclusion. However, many
times we may need to actively experiment to obtain more data,
perhaps because we found that our model is wrong.
}



\begin{frame}
  \frametitle{Can machines learn from their mistakes?}
  \begin{center}
    \includegraphics[width=0.7\textwidth]{../figures/rl_interaction}
  \end{center}
  \begin{block}{Reinforcement learning}
    Take actions $a_1, \ldots, a_t$, so as to maximise utility
    $U = \sum_{t=1}^T r_t$
  \end{block}
\end{frame}


\only<article>{
So, what happens when we make a mistake? Can we somehow recognise
it? Humans and other animals can actually learn from their
mistakes. Consider the proverbial rat in the maze. At some
intervals, the experimenter places some cheese in there, and the
rat must do a series of actions to obtain it, such as navigating
the maze and pulling some levers. It doesn't know how to get to
the cheese easily, but it slowly learns the layout of the maze
through observation, and in the end, through trial-and-error it
is able to get to the cheese very efficiently.

We can formalise this as a reinforcement learning problem, where
the rat takes a series of actions; at each step it also obtains a
reward, let's say equal to 0 when it has no cheese, and 1 when it
eats cheese. Then we can declare that the rat's utility is the sum
of all rewards over time, i.e. the total amount of cheese it can
eat before it dies. The rat needs to explore the environment in order to be able to
get to the cheese. 

An example in robotics is trying to teach a
robot to flip pancakes. One easy thing we can try is to show the robot
how to do it, and then let it just copy the demonstrated
movement. However, this doesn't work! The robot needs to explore
variations of the movement, until it manages to successfully flip
pancakes. Again, we can formulate this as a reinforcement learning
problem, with a reward that is high whenever the pancake's position is
flipped, and on the pan; and low everywhere else. Then the robot can
learn to perform this behaviour through trial and error. It's
important to note that in this example, merely demonstration is not
enough. Neither is reinforcement learning enough. The same thing is
true for the recent success of AlphaGo in beating a master human:
apart from planning, they used both demonstration data and self-play,
so that it could learn through trial and error.  }

\begin{frame}
  \frametitle{Can machines make complex plans?}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{../figures/619px-FloorGoban}
  \end{center}
\end{frame}


\only<article>{
 I suppose the first question is whether machines can plan
 ahead. Indeed, even for large problems, such as Go, machines can
 now perform at least as well as top-rated humans. How is this
 achieved?
}

\begin{frame}
  \frametitle{Machines can make complex plans!}
  \begin{center}
    \includegraphics[width=0.8\textwidth]{../figures/Tic-tac-toe-game-tree}
  \end{center}
\end{frame}


\only<article>{
The basic construction is the planning tree. This is an enumeration
of all possible future events. If a complete enumeration is
impossible, a partial tree is constructed. However this requires
evaluating non-terminal game positions. In the old times, this was
done with heuristics, but now this is data-driven, both through the
use of expert databases, and through self-play and reinforcement
learning.
}


\subsection{Experiment design}

\only<presentation>{
  \begin{frame}
    \centering
    \Huge{The scientific process as machine learning}
  \end{frame}
  \begin{frame}
    \centering
    \includegraphics[width=\textwidth]{../figures/Las_Vegas_slot_machines}
  \end{frame}
}


\only<article>{
An example that typifies trial and error learning are bandit
problems. Imagine that you are in a Casino and you wish to
maximise the amount of money you make during the night. There are
a lot of machines to play. If you knew which one was the best,
then you'd just play it all night long. However, you must also
spend time trying out different machines, in order to get an
estimate of how much money each one gives out. The trade off
between trying out different machines and playing the one you
currently think is best is called the exploration-exploitation
trade-off and it appears in many problems of experiment design for
science.
}


\begin{frame}
  \frametitle{Adam, the robot scientist}
  \centering
  \includegraphics[width=0.8\textwidth]{../figures/robot-scientist}
\end{frame}


\only<article>{
 Let's say we want to build a robot scientist and tell it to
 discover a cure for cancer. What does the scientist do and how can the robot replicate it??
}



\begin{frame}
  \frametitle{Drug discovery}
  \centering
  \includegraphics[width=\columnwidth]{../figures/drug-discovery-000}
\end{frame}


\only<article>{
Simplifying the problem a bit, consider that you have a large
number of drug candidates for cancer and you wish to discover
those that are active against it. The ideas is that you select
some of them, then screen them, to sort them into active and
inactive. However, there are too many drugs to screen, so the
process is interactive. At each cycle, we select some drugs to
screen, classify them, and then use this information to select
more drugs to screen. This cycle, consequently has two parts:
1. Selecting some drugs given our current knowledge.
2. Updating our knowledge given new evidence.
}


\begin{frame}
  \frametitle{Drawing conclusions from results}
  \centering
  \begin{tikzpicture}[line width=2pt]
    \node at (0,0) (bt) {hypothesis};
    \node[select] at (0,2) (at) {experiment};
    \node[utility] at (3,-2) (rt) {result};
    \draw[blue,->] (at) -- (rt);
    \node at (4,0) (bt2) {conclusion};
    \draw[red,->] (at) -- (bt2);
    \draw[red,->] (bt) -- (bt2);
    \draw[red,->] (rt) -- (bt2);
  \end{tikzpicture}
\end{frame}

\only<article>{
  In general, we would like to have some method which can draw
  conclusions from results. This involves starting with a
  hypothesis, performing an experiment to verify or refute it,
  obtain some experimental result; and then concluding for or
  against the hypothesis. Here the arrows show dependencies
  between these variables. So what do we mean by "hypothesis" in this case?
}

\subsection{Bayesian inference.}
\begin{frame}
  \frametitle{Tycho Brahe's minute eye measurements}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=0.5\textwidth]{../figures/circular-orbits}
    \end{column}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=0.5\textwidth]{../figures/tycho-observations}
    \end{column}
  \end{columns}
  \begin{itemize}
  \item Hypothesis: Circular orbits
  \item Conclusion: \alert{Specific} circular orbits
  \end{itemize}
\end{frame}


\only<article>{
  Let's take the example of planetary orbits. Here Tycho famously
  spent 20 years experimentally measuring the location of Mars. He
  had a hypothesis: that planetary orbits were circular, but he
  didn't know which were the right orbits. When he tried to fit his data to this hypothesis, he concluded a specific circular orbit for Mars \ldots around Earth.
}


\begin{frame}
  \frametitle{Johannes Kepler's alternative hypothesis}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=0.5\textwidth]{../figures/orbits}
    \end{column}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=0.5\textwidth]{../figures/tycho-observations}
    \end{column}
  \end{columns}
  \begin{itemize}
  \item Hypothesis: Circular \alert{or} elliptic orbits
  \item Conclusion: Specific \alert{elliptic} orbits
  \end{itemize}
\end{frame}


\only<article>{
Kepler had a more general hypothesis: that orbits could be
circular or elliptic, and he actually accepted that the planets
orbited the sun. This led him to the broadly correct model of all
planets being in elliptical orbits around the sun. However, the
actual verification that all things do not revolve around earth,
requires different experiments.
}


\begin{frame}
  \frametitle{200 years later, Gauss formalised this statistically}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\columnwidth]{../figures/gauss-diagram}
    \end{column}
    \begin{column}{0.5\textwidth}
      \includegraphics[width=\columnwidth]{../figures/SeptemberTable}
    \end{column}
  \end{columns}
\end{frame}


\only<article>{
Later on, Gauss collected even more experimental data to calculate the orbit of Ceres. He did this using one of the first formal statistical methods; this allowed him to avoid cheating (like Kepler did, to accentuate his finding that orbits were elliptical).
}


\begin{frame}
  \frametitle{A warning: The dead salmon mirage}
  \includegraphics[width=\textwidth]{../figures/fmri-salmon}
\end{frame}


\only<article>{
It is quite easy to draw the wrong conclusions from applying
machine learning / statistics to your data. For example, it was
fashionable to perform fMRI studies in humans to see whether some
neurons have a particular functional role. There were even
articles saying that "we found the neurons encoding for Angelina
Jolie". So some scientists tried to replicate those results. They
took a dead salmon, and put it an fMRI scanner. They checked its
brain activity when it was shown images of happy or sad
people. Perhaps surprisingly, they found an area of the brain that
was correlated with the pictures - so it seemed, as though the
dead salmon could distinguish photos of happy people from sad
ones. However, this was all due to a misapplication of
statistics. In this course, we will try and teach you to avoid
such mistakes.
}


\begin{frame}
  \frametitle{Planning future experiments}
  \centering
  \begin{tikzpicture}[line width=2pt]
    \node at (0,0) (bt) {hypothesis};
    \node[select] at (0,2) (at) {experiment};
    \node[utility] at (3,-2) (rt) {result};
    \draw[blue,->] (at) -- (rt);
    \node at (4,0) (bt2) {conclusion};
    \draw[red,->] (at) -- (bt2);
    \draw[red,->] (bt) -- (bt2);
    \draw[red,->] (rt) -- (bt2);
  \end{tikzpicture}
\end{frame}

\only<article>{
I mentioned before that we must decide what experiment to do. This is indeed difficult, especially in setting such as drug discovery where the number of experiments is huge.  However, conceptually, there is a simple and elegant solution to this problem.
}


\begin{frame}
  \frametitle{Planning experiments is like Tic-Tac-Toe}
  \begin{center}
    \includegraphics[width=\textwidth]{../figures/Tic-tac-toe-game-tree}
  \end{center}
\end{frame}


\only<article>{
  The basic idea is to think of experiment design as a game between the scientist and Nature. At every step, the scientist plays an X to  denote an experiment. Then Nature responds with an Observation. The main difference from a game is that Nature is (probably) not adversarial. We can also generalise this idea to problems in robotics, etc.
}

\only<presentation>{
\begin{frame}
  \frametitle{Eve, another robot scientist}
  \centering \movie{\includegraphics[width=\textwidth]{../figures/eve.jpg}}{Eve-video.mp4}
  Discovered a malaria drug
\end{frame}
}
\only<article>{
 These kinds of techniques, coming from the reinforcement learning literature have been successfully used at the university of Manchester to create a robot, called Eve, that recently (re)-discovered a malaria drug.
}

\subsection{Course overview}

\begin{frame}
  \frametitle{Machine learning in practice}
  \begin{block}{Avoiding pitfalls}
    \begin{itemize}
    \item Choosing hypotheses.
    \item Correctly interpreting conclusions.
    \item Using a good testing methodology.
    \end{itemize}
  \end{block}
  \begin{block}{Machine learning in society}
    \begin{itemize}
    \item<alert@2> Privacy \uncover<2->{--- Medical data.}
    \item<alert@3> Fairness \uncover<3->{--- Credit risk.}
    \item<alert@4> Safety \uncover<4->{--- Autonomous vehicles.}
    \end{itemize}
  \end{block}
\end{frame}

\only<article>{
One of the things we want to do in this course is teach you to
avoid common pitfalls.

Now I want to get into a different track. So far everything has
been about pure research, but now machine learning is pervasive:
Our phones, cars, watches, bathrooms, kettles are connected to the
internet and send a continuous stream of data to companies. In
addition, many companies and government actors use machine
learning algorithms to make or support decisions. This creates a
number of problems in privacy, fairness and safety.
}


\begin{frame}
  \frametitle{Technical topics}
  
  \begin{block}{Machine learning problems}
    \begin{itemize}
    \item Unsupervised learning.
    \item Supervised learning.
    \item Reinforcement learning.
    \end{itemize}
  \end{block}

  \begin{block}{Machine learning tools}
    \begin{itemize}
    \item Stochastic optimisation and neural networks.
    \item Probabilistic inference and Bayesian networks.
    \item Markov decision processes.
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Course structure}
  \begin{block}{Module structure}
    \begin{itemize}
    \item \alert{Activity}-based, hands-on.
    \item Background reading \alert{before} class.
    \item Mini-lecture with \alert{Q/A} at each class.
    \item Small \alert{group project} in second half of class.
    \end{itemize}
  \end{block}

  \begin{block}{Modules}
    \begin{itemize}
    \item Medical diagnostics.
    \item Speech recognition.
    \item Recommendation systems.
    \item Helicopter flight.
    \end{itemize}
  \end{block}
\end{frame}


\section{Nearest neighbours}
\begin{frame}
  \frametitle{Discriminating between diseases}
  \input{../figures/KNN3.tikz}
\end{frame}

\only<article>{
  Let's tackle the problem of discriminating between different
disease vectors. Ideally, we'd like to have a simple test that
tells us what ails us. One kind of test is mass spectrometry. This
graph shows spectrometry results for two types of bacteria. There
is plenty of variation within each type, both due to measurement
error and due to changes in the bacterial strains. Here, we plot
the average and maximum energies measured for about 100 different
examples from each strain.
}

\begin{frame}
  \frametitle{Nearest neighbour: the hidden secret of machine learning}
  \input{../figures/separation1.tikz}
\end{frame}

\only<article>{
  Now, is it possible to identify an unknown strain based on this
data? Actually, this is possible. Sometimes, very simple algorithms
work very well. One of the simplest one involves just measuring the
distance between the decsription of a new unknown strain and known
ones. In this visualisation, I projected the 1300-dimensional data
into a 2-dimensional space. Here you can clearly see that it is
possible to separate the two strains. In order to classify a new
point, you just need to see whether it's closer to the train VVT or
BUT.
}

\begin{frame}
\frametitle{Comparing spectral data}
  \only<1>{\input{../figures/difference1.tikz}}
  \only<2>{\input{../figures/difference2.tikz}}
\end{frame}
\only<article>{
The choice of distance in this kind of algorithm is important,
particularly for very high dimensions. For something like a
spectrogram, one idea is look at the total area of the difference
between two spectral lines. 
}
\begin{frame}
  \frametitle{Nearest neighbour: What type is the new bacterium?}
  \input{../figures/separation2.tikz}
  \only<presentation>{
    \only<2>{\Large \alert{What if it a \textbf{completely different strain}?}}
  }
\end{frame}

\begin{frame}
  \frametitle{Hands on with Python console}
  

\end{frame}

\begin{frame}
  \frametitle{What have we learned}
  \begin{block}{Machine Learning background}
    \begin{itemize}
    \item Many \alert{technical} problem types.
    \item \alert{Scientific} applications.
    \item \alert{Societal} issues.
    \item Machine learning as science.
    \end{itemize}
  \end{block}

  \begin{block}{Methodology}
    \begin{itemize}
    \item \alert{Classification} Problems: \only<3->{$k$-nearest neighbour algorithm.}
    \item Elementary \alert{variable selection}.
    \item \alert{Verifying} your \alert{conclusions}: \only<3->{Validation/Test sets.}
    \item Verifying your \alert{assumptions}: \only<4->{(How?)}
    \end{itemize}
  \end{block}
\end{frame}

\section{Decision problems}

\only<article>{
All machine learning problems are essentially decision problems. This essentially means replacing some human decisions with machine decisions. One of the simplest decision problems is classification, where you want an algorithm to decide the correct class of some data, but even within this simple framework there is a multitude of decisions to be made. The first is how to frame the classification problem the first place. The second is how to collect, process and annotate the data. The third is choosing the type of classification model to use. The fourth is how to use the collected data to find an optimal classifier within the selected type. After all this has been done, there is the problem of classifying new data. In this course, we will take a holistic view of the problem, and consider each problem in turn, starting from the lowest level and working our way up.}

\section{Hierarchies of decision making problems}
\begin{frame}
  \tableofcontents[currentsection]
\end{frame}
\subsection{Simple decision problems}
\begin{frame}
  \frametitle{Preferences}

  \begin{example}
    \begin{block}{Food}
      \begin{itemize}
      \item[A] McDonald's cheeseburger
        \item[B] Surstromming
        \item[C] Oatmeal
        \end{itemize}
      \end{block}
      \begin{block}{Money}
        \begin{itemize}
        \item[A] 10,000,000 SEK
        \item[B] 10,000,000 USD
        \item[C] 10,000,000 BTC
        \end{itemize}
      \end{block}
      \begin{block}{Entertainment}
        \begin{itemize}
        \item[A] Ticket to Liseberg
        \item[B] Ticket to Rebstar
        \item[C] Ticket to Nutcracker
        \end{itemize}
      \end{block}
  \end{example}

  \only<article>{The simplest decision problem involves selecting one item from a set of choices.}  
  \begin{itemize}
  \item Each choice is called a \alert{reward} $r \in \CR$.
  \item There is a \alert{utility function} $U : \CR \to \Reals$, assigning values to reward.
  \item We (weakly) prefer $A$ to $B$ iff $U(A) \geq U(B)$.
  \end{itemize}

  \begin{exercise}
    From your individual preferences, derive a \alert{common utility function} that reflects everybody's preferences in the class.
  \end{exercise}
\end{frame}


\begin{frame}
  \frametitle{Uncertain rewards}
  \only<article>{However, in real life, there are many cases where we can only choose between uncertain outcomes. The simplest example are lottery tickets, where rewards are essentially random. However, in many cases the rewards are not really random, but simply uncertain. In those cases it is useful to represent our uncertainty with probabilities as well, even though there is nothing really random.}
  \begin{example}%ro: rather an exercise?
    You are going to work, and it might rain.
    What do you do?
    \begin{itemize}
    \item $\decision_1$: Take the umbrella.
    \item $\decision_2$: Risk it!
    \item $\outcome_1$: rain
    \item $\outcome_2$: dry
    \end{itemize}
    \begin{table}
      \centering
      \begin{tabular}{c|c|c}
        $\Rew(\outcome,\decision)$ & $\decision_1$ & $\decision_2$ \\ %ro: U has only one argument.
        \hline
        $\outcome_1$ & dry, carrying umbrella & wet\\
        $\outcome_2$ & dry, carrying umbrella & dry\\
        \hline
        \hline
        $U[\Rew(\outcome,\decision)]$ & $\decision_1$ & $\decision_2$ \\
        \hline
        $\outcome_1$ & 0 & -10\\
        $\outcome_2$ & 0 & 1
      \end{tabular}
      \caption{Rewards and utilities.}
      \label{tab:rain-utility-function}
    \end{table}

    \begin{itemize}
    \item<2-> $\max_\decision \min_\outcome U = 0$
    \item<3-> $\min_\outcome \max_\decision  U = 0$
    \end{itemize}
  \end{example}
\end{frame}



\begin{frame}
  \frametitle{Expected utility}
  \[
    \E (U \mid a) = \sum_r U[\Rew(\outcome, \decision)] \Pr(\outcome \mid \decision)
  \]
  \begin{example}%ro: rather an exercise?
    You are going to work, and it might rain. The forecast said that
    the probability of rain $(\outcome_1)$ was $20\%$. What do you do?
    \begin{itemize}
    \item $\decision_1$: Take the umbrella.
    \item $\decision_2$: Risk it!
    \end{itemize}
    \begin{table}
      \centering
      \begin{tabular}{c|c|c}
        $\Rew(\outcome,\decision)$ & $\decision_1$ & $\decision_2$ \\ %ro: U has only one argument.
        \hline
        $\outcome_1$ & dry, carrying umbrella & wet\\
        $\outcome_2$ & dry, carrying umbrella & dry\\
        \hline
        \hline
        $U[\Rew(\outcome,\decision)]$ & $\decision_1$ & $\decision_2$ \\
        \hline
        $\outcome_1$ & 0 & -10\\
        $\outcome_2$ & 0 & 1\\
        \hline
        \hline
        $\E_P(U \mid \decision)$ & 0 &  -1.2 \\ 
      \end{tabular}
      \caption{Rewards, utilities, expected utility for $20\%$ probability of rain.}
      \label{tab:rain-utility-function}
    \end{table}
  \end{example}
\end{frame}

\begin{frame}
  \frametitle{Preferences among random outcomes}
  \begin{example}
    Would you rather \ldots
    \begin{itemize}
    \item[A] Have 100 EUR now?
    \item[B] Flip a coin, and get 200 EUR if it comes heads?
    \end{itemize}    
  \end{example}
  \uncover<2->{
    \begin{block}{The expected utility hypothesis}
      Rational decision makers prefer choice $A$ to $B$ if
      \[
        \E(U | A) \geq \E(U | B),
      \]
      where the expected utility is
      \[
        \E(U | A) = \sum_r U(r) \Pr(r | A).
      \]
    \end{block}
    In the above example, $r \in \{0, 100, 200\}$ and $U(r)$ is
    increasing, and the coin is fair.
  }
  \begin{itemize}
  \item<3-> If $U$ is convex, we prefer B.
  \item<4-> If $U$ is concave, we prefer A.
  \item<5-> If $U$ is linear, we don't care.
  \end{itemize}
\end{frame}




\subsection{Decision rules}
\only<presentation>{
  \begin{frame}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}
\only<article>{We now move from simple decisions to decisions that
  depend on some observation. This is most easily embodied through the
  problem of classification. }
\begin{frame}
  \frametitle{Deciding a class given a model}
  \only<article>{In the simplest classification problem, we observe some features $x_t$ and want to make a guess $\decision_t$ about the true class label $y_t$. Assuming we have some probabilistic model $P(y_t \mid x_t)$, we want to define a decision rule $\pol(\decision_t \mid x_t)$ that is optimal, in the sense that it maximises expected utility for $P$.}
  \begin{itemize}
  \item Features $x_t \in \CX$.
  \item Label $y_t \in \CY$.
  \item Decisions $\decision_t \in \CA$.
  \item Decision rule $\pol(\decision_t \mid x_t)$ assigns probabilities to actions.
  \end{itemize}
  
  \begin{block}{Standard classification problem}
    \only<article>{In the simplest case, the set of decisions we make are the same as the set of classes}
    \[
    \CA = \CY, \qquad
    U(\decision, y) = \ind{\decision = y}
    \]
  \end{block}

  \begin{exercise}
    If we have a model $P(y_t \mid x_t)$, and a suitable $U$, what is the optimal decision to make?
  \end{exercise}
  \only<presentation>{
    \uncover<2->{
      \[
      \decision_t \in \argmax_{\decision \in \Decisions} \sum_y P(y_t = y \mid x_t) \Util(\decision, y)
      \]
    }
    \uncover<3>{
      For standard classification,
      \[
      \decision_t \in \argmax_{\decision \in \Decisions} P(y_t = \decision \mid x_t)
      \]
    }
  }
\end{frame}


\begin{frame}
  \frametitle{Deciding the class given a model family}
  \begin{itemize}
  \item Training data $S = (x_1, y_1, \ldots, x_n, y_n)$
  \item Models $\cset{P_\outcome}{\outcome \in \Outcome}$
  \item Prior $\bel$ on $\Outcome$.
  \end{itemize}
  \[
    \bel(\outcome \mid S)
    = \frac{P_\outcome(y_1, \ldots, y_n \mid x_1, \ldots, x_n) \bel(\outcome)}
    {\sum_{\outcome' \in \Outcome} P_{\outcome'}(y_1, \ldots, y_n \mid x_1, \ldots, x_n) \bel(\outcome')}
  \]
  We can then calculate the posterior marginal marginal label probability
  \[
    P_{\bel \mid S}(y_t \mid x_t) \defn
    P_{\bel}(y_t \mid x_t, S) = 
    \sum_{\outcome \in \Outcome} P_\outcome(y_t \mid x_t) \bel(\omega \mid S).
  \]
  We can then construct the following simple decision rule:
  \[
    \decision_t \in \argmax_{\decision \in \CY}\sum_{\outcome \in \Outcome} P_\outcome(y_t \mid x_t) \bel(\omega \mid S),
  \]
  otherwise known as the \alert{Bayes rule}.
\end{frame}

\section{Bayes decisions}
\begin{frame}
  \frametitle{Bayes decision rules}
  Consider the case where outcomes are independent of decisions:
  \[
    \Util (P, \decision) \defn \sum_{\outcome}  \Util (\outcome, \decision) P(\outcome)
  \]
  This corresponds e.g. to the case where $P(\omega)$ is the belief about an unknown world.
  \begin{definition}[Bayes utility]
    \label{def:bayes-utility}
    The maximising decision for $P$ has an expected utility equal to:
    \begin{equation}
      \BUtil(P) \defn \sup_{\decision \in \Decisions} \Util (P, \decision).
      \label{eq:bayes-utility}
    \end{equation}
  \end{definition}
\end{frame}


\only<article>{
  One of the simplest decision problems is classification. At the simplest level, this is the problem of observing some data point $x_t \in \CX$ and making a decision about what class $\CY$ it belongs to. Typically, a fixed classifier is defined as a decision rule $\pi(a | x)$ making decisions $a \in \CA$, where the decision space includes the class labels, so that if we observe some point $x_t$ and choose $a_t = 1$, we essentially declare that $y_t = 1$.

  Typically, we wish to have a classification policy that minimises classification error.
}
\begin{frame}
  \begin{definition}[Classification error of a fixed decision rule]
    
  \end{definition}
\end{frame}


\bibliographystyle{apalike}
\bibliography{../../bib/mine,../../bib/misc}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
