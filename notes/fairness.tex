\section{Fairness in machine learning}

\only<article>{
  The problem of fairness in machine learning and artificial intelligence has only recently been widely recognised. When any algorithm is implemented at scale, no matter the original objective and whether it is satisfied, it has significant societal effects. In particular, even when considering the narrow objective of the algorithm, even if it improves it overall, it may increase inequality.

  In this course we will look at two aspects of fairness. The first has to do with disadvantaged populations that form distinct social classes due to a shared income stratum, race or gender. The second has to do with meritocratic notions of fairness.
}
\begin{frame}
  \frametitle{Bail decisions}
  \only<article>{
    For our example regarding disadvantaged populations, consider the example of bail decisions in the US court system. When a defendant is charged, the judge has the option to either place them in jail pending trial, or set them free, under the condition that the defendant pays some amount of bail. The amount of bail (if any) is set to an amount that would be expected to deter flight or a relapse. 
  }

  \only<presentation>{
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \centering
      \begin{tikzpicture}
        \node at (0,0) (judge) {\includegraphics[width=0.3\columnwidth]{../figures/judge}};
        \uncover<2->{
          \node at (-2,-2) (jail) {\includegraphics[width=0.3\columnwidth]{../figures/jail}};
          \draw[->] (judge) -- (jail);
        }
        \uncover<3->{
          \node at (2,-2) (bail) {\includegraphics[width=0.3\columnwidth]{../figures/bail}};
          \draw[->] (judge) -- (bail);
        }

        \uncover<4->{
          \node at (-2,-4) (trial) {\includegraphics[width=0.3\columnwidth]{../figures/trial}};
          \draw[->] (jail) -- (trial);
        }
        \uncover<5->{
          \draw[->] (bail) -- (trial);
        }
        \uncover<6->{
          \node at (2,-4) (arrest) {\includegraphics[width=0.3\columnwidth]{../figures/handcuffs}};
          \draw[->] (bail) -- (arrest);
        }
      \end{tikzpicture}
    \end{column}
    \begin{column}{0.5\textwidth}
      \centering
      \uncover<7->{
        \includegraphics[width=\textwidth]{../figures/judge-fairness}
      }
    \end{column}
  \end{columns}
}
    
\only<article>{
  \begin{figure}
    \includegraphics[width=\textwidth]{../figures/judge-fairness}
    \caption{In some cases, it appears as though automating this procedure might lead to better outcomes. But is that generally true?}
    \label{fig:judge-fairness}
  \end{figure}
}

\end{frame}

\begin{frame}
  \frametitle{Whites get lower scores than blacks\footnote{Pro-publica, 2016}}
  \only<article>{In a different study, it was shown that a commonly used software tool for determining 'risk scores' in the US was biased towards white defendants, who seemed to be always getting lower scores than blacks.}
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \centering
      \def\svgwidth{\columnwidth}
      \input{../figures/risk-scores-black.pdf_tex}
      Black
    \end{column}
    \begin{column}{0.5\textwidth}
      \centering
      \def\svgwidth{\columnwidth}
      \input{../figures/risk-scores-white.pdf_tex}      
      White
    \end{column}
  \end{columns}
  \uncover<2>{Does this mean there is a bias?}
\end{frame}

\begin{frame}
  \frametitle{But scores equally accurately predict recidivsm\footnote{Washington Post, 2016}}
    \only<article>{On the other hand, the scores generated by the software seemed to be very predictive on whether or not defendants would re-offend, independently of their race.}
  \centering
  \includegraphics[width=\columnwidth]{../figures/imrs}

\end{frame}
\begin{frame}
  \frametitle{But non-offending blacks get higher scores}
  \only<article>{On the third hand, we see that the system seemed to give higher risk scores to non-offending blacks. So, is there a way to fix that or not?}
  \centering
  \includegraphics[width=\columnwidth]{../figures/imrs-risk}
\end{frame}

\begin{frame}
  \frametitle{Bail decisions, revisited}
  \only<article>{Let us think of this problem in terms of bail decisions made by a judge using some policy $\pol$ with $\pol(a \mid x)$ being the probability that the judge decides $a$ when she observes $x$. Let $y$ be the outcome, which may or may not depend on $a$. In this particular case, $a$ is either release or jail. And $y$ is appears for trial or not. If we accept the tenets of decision theory, there is also a utility function defined on which the judge bases her decision.}
  \centering
  \begin{columns}
    \begin{column}{0.5\textwidth}
      \begin{tikzpicture}
        \node[label=$x$] at (-1,2) (person)
        {\includegraphics[width=0.2\columnwidth]{../figures/me-recent}};
        \node[label=$\pi$] at (0,0) (judge) {\includegraphics[width=0.3\columnwidth]{../figures/judge}};
        \draw[->] (person) -- (judge);
        \uncover<2->{
          \node[label=$a_1$] at (-2,-2) (jail) {\includegraphics[width=0.3\columnwidth]{../figures/jail}};
          \draw[->] (judge) -- (jail);
        }
        \uncover<3->{
          \node[label=$a_2$] at (2,-2) (bail) {\includegraphics[width=0.3\columnwidth]{../figures/bail}};
          \draw[->] (judge) -- (bail);
        }
        \uncover<4->{
          \node[label=$y_1$] at (-2,-4) (trial) {\includegraphics[width=0.3\columnwidth]{../figures/trial}};
          \draw[->] (jail) -- (trial);
        }
        \uncover<5->{
          \draw[->] (bail) -- (trial);
        }
        \uncover<6->{
          \node[label=$y_2$] at (2,-4) (arrest) {\includegraphics[width=0.3\columnwidth]{../figures/handcuffs}};
          \draw[->] (bail) -- (arrest);
        }
      \end{tikzpicture}
    \end{column}
    \begin{column}{0.5\textwidth}
      \uncover<2->{\[\pi(a \mid x) \tag{policy}\]}
      \uncover<4->{\[\Pr(y \mid a, x) \tag{outcome}\]}
      \uncover<7->{\[U(a,y) \tag{utility}\]}
    \end{column}
  \end{columns}
\end{frame}


\begin{frame}
  \frametitle{Fairness as independence}
  \only<article>{So how can we reframe the above fairness notions in a more precise way? Both of them involve conditional independence between $y, a$ and a sensitive attribute $z$, such as race. The first notion says that the actions of the judge (or equivalently, the scores of the algorithm) are \emph{calibrated} with respect to the outcomes. The second says that they are \emph{balanced}, so that were the outcome known to the judge, she would be making a decision independently of the defendant's race.}
  \only<1>{
    \includegraphics[width=\columnwidth]{../figures/imrs}
  }
  \only<2>{
    \includegraphics[width=\columnwidth]{../figures/imrs-risk}
  }
  \begin{columns}
    \begin{column}{0.3\textwidth}
      \begin{itemize}
      \item[$y$] Result.
      \item[$a$] Assigned score.
      \item[$z$] Race.
      \end{itemize}
    \end{column}
    \begin{column}{0.7\textwidth}
      \begin{align}
        \Pr^\pi(y \mid a, z) &= \Pr^\pi(y \mid a) \tag{\alert<1>{calibration}}\\
        \Pr^{\pi}(a \mid y, z) &= \Pr^{\pi}(a \mid y) \tag{\alert<2>{balance}}
      \end{align}
    \end{column}
  \end{columns}
  \only<article>{
    You will observe that calibration here means that
    \[
      y \indep z \mid a,
    \]
    i.e. that $y$ is independent of $z$ given the judge's action $a$.
    On the other hand, balance means that
    \[
      a \indep z \mid y,
    \]
    i.e. that $a$ is independent of $z$ given the true outcome $y$.\footnote{This definition only really makes sense when $y$ does not depend on $a$ at all. When this is not the case, it's easy to construct a random variable $y'$ that does not depend on $a$ so that $y$ can be written as a function $y(y', a)$. Then we can achieve balance with respect to $y'$.}
  }
\end{frame}

\begin{frame}
  \frametitle{Fairness as similarity.}
  \only<article>{Another idea of fairness has to do with meritocracy. If one candidate is better than another, shouldn't that candidate be always preferred? How can we formalise this?}
  \begin{block}{Find a policy $\pol$ that}
    \begin{itemize}
    \item Maximises utility $\util$.
    \item Makes similar decisions $a$ for people with similar data $x,x'$
    \end{itemize}
  \end{block}
  \centering
  \begin{tikzpicture}[scale=2,thick,domain=-2:2]
    \draw[->] (-2,0) -- (2,0) node[right] {$x$};
    \draw[->] (0,0) -- (0,1) node[above] {$\pol(a \mid x)$};
    \draw[color=blue] plot (\x,{0.5 + 0.5 * tanh(\x)}); % node[right] {$f(x) = \frac{1}{20} \mathrm e^x$};
    \draw [|<->|,color=red] plot (-0.5,-0.1) -- node[below=1em] {$\rho(x,x')$} ++(1, 0);
  \end{tikzpicture}
\end{frame}

\begin{frame}
  \frametitle{Summary of fairness conditions}
  \begin{itemize}
  \item<1-> Calibration: Given decision, outcome doesn't depend on race.
  \item<2-> Balance: Given outcome,  decision doesn't depend on race.
  \item<3-> Similarity: Similar people should be treated similarly.
  \item<4-> Meritocracy: Better people should be treated better.
  \end{itemize}

  \begin{alertblock}{Open issues}
    \begin{itemize}
    \item<5-> Can these conditions be satisfied when $\param$ is unknown?
    \item<6-> What is ``similar'' anyway?
    \end{itemize}
  \end{alertblock}
  \uncover<7>{Our solutions: Subjective fairness and informational similarity.}
\end{frame}

\begin{frame}
  \frametitle{The Bayesian fairness framework}
  \begin{center}
    \includegraphics[width=0.5\textwidth]{../figures/bias}

    From prior and data $\Rightarrow$ belief
    $\bel(\param)$
  \end{center}
  
   \begin{definition}[Bayes rule]
     The optimal decision rule simply maximises expected utility:
     \begin{align}
       \pol^*(a \mid x) &= \argmax_a \E_\bel(U \mid a, x)
       \\
       \E_\bel(U \mid a, x) &= \int_\Param \E_\param(U \mid a, x) \dd \bel(\param)
     \end{align}
   \end{definition}
\end{frame}
\begin{frame}
  \frametitle{Example: Balanced decision rules.}
  \begin{definition}[Balanced decision rule]
    A decision rule $\pol$ is balanced with respect to $\param$ if
  \begin{align*}
    C_\param^\pol(y,z) &\defn \Pr_\param^\pol(a, z \mid y) -  \Pr_\param^\pol(a  \mid y)  \Pr_\param^\pol(z  \mid y) = 0 &&\forall x, y, z
  \end{align*}
  i.e. $a \indep z \mid y, \pol, \param$.
\end{definition}

\begin{block}{When $\param$ is unknown}

      \[
        \max_\pol \int_\Param \dd \bel(\param) [U(\param, \pol) - \lambda \max_{y, z} C_\param^\pol(y,z)]
      \]
    \end{block}
    where $\Delta$ measures dependence.
\end{frame}

\begin{frame}
\frametitle{Informational fairness}

  ``Similar people should be treated similarly''

  \begin{tikzpicture}[scale=2,thick,domain=-2:2]
    \draw<1->[->] (-2,0) -- (2,0) node[right] {$y$};
    \draw<1->[->] (0,0) -- (0,1);
    \draw<2->[color=blue] plot (\x,{exp(-(\x - 1)^2)}) node[right] {$\Pr_{\bel}(y|x)$};
    \draw<3->[color=red] plot (\x,{exp(-(\x + 1)^2)}) node[above] {$\Pr_{\bel}(y|x')$};
  \end{tikzpicture}
  \uncover<4->{
    \begin{block}{Thompson sampling}
      \begin{itemize}
      \item $\hat{\param} \sim \bel$
      \item $a = \argmax_a \E_{\hat{\param}} [U \mid x, a]$
      \end{itemize}
    \end{block}
    \begin{block}{Stochastic dominance sampling}
      \begin{itemize}
      \item $\hat{\param} \sim \bel$
      \item $\hat{y} \sim \Pr_\param$
      \item $\pol(a | x) = \argmax_a U(\hat{y},a)$
      \end{itemize}
    \end{block}
    
  }
\end{frame}

\begin{frame}
  \frametitle{Current status}
  \begin{itemize}
  \item Link between smoothness and independence under uncertainty.
  \item Optimality of Thompson sampling with respect to subjective meritocracy.
  \item Introduced calibrated fairness for which stochastic dominance is optimal.
  \item Application to bandit problems.
  \item More general decision settings are an open problem.
  \end{itemize}

\end{frame}







%%% Local Variables:
%%% mode: latex
%%% TeX-engine: xetex
%%% TeX-master: "notes"
%%% End:
